{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "response_selection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkrrojOVjOv8"
      },
      "source": [
        "!pip install conversational-sentence-encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPncIf7VjQzl"
      },
      "source": [
        "from conversational_sentence_encoder.vectorizers import SentenceEncoder\r\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yygmHhEvjtwR"
      },
      "source": [
        "# initialize the ConveRT dual-encoder model\r\n",
        "sentence_encoder = SentenceEncoder(multiple_contexts=False)\r\n",
        "\r\n",
        "questions = np.array([\"where is my order?\", \r\n",
        "                      \"what is the population of London?\",\r\n",
        "                      \"will you pay me for collaboration?\"])\r\n",
        "\r\n",
        "# outputs 512 dimensional vectors, giving the context representation of each input. \r\n",
        "#These are trained to have a high cosine-similarity with the response representations of good responses\r\n",
        "questions_encoded = sentence_encoder.encode_contexts(questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFW4f5ZL7D3i"
      },
      "source": [
        "responses = np.array([\"we expect you to work for free\",\r\n",
        "                      \"there are a lot of people\",\r\n",
        "                      \"its on your way\"])\r\n",
        "\r\n",
        "# outputs 512 dimensional vectors, giving the response representation of each input. \r\n",
        "#These are trained to have a high cosine-similarity with the context representations of good corresponding contexts\r\n",
        "responses_encoded = sentence_encoder.encode_responses(responses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX6G5J-F69lG"
      },
      "source": [
        "# computing pairwise similarities as a dot product\r\n",
        "similarity_matrix = questions_encoded.dot(responses_encoded.T)\r\n",
        "\r\n",
        "# indices of best answers to given questions\r\n",
        "best_idx = np.argmax(similarity_matrix, axis=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO9QGcld6_d_"
      },
      "source": [
        "# will output answers in the right order\r\n",
        "# ['its on your way', 'there are a lot of people', 'we expect you to work for free']\r\n",
        "print(np.array(responses)[best_idx])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}